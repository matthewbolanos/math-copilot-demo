environment:
  python_requirements_txt: requirements.txt
inputs:
  chat_history:
    type: list
    is_chat_history: true
    default: []
  question:
    type: string
    is_chat_input: true
outputs:
  answer:
    type: string
    reference: ${chat.output}
    is_chat_output: true
nodes:
- name: chat
  type: llm
  source:
    type: code
    path: chat.jinja2
  inputs:
    deployment_name: gpt-35-turbo
    max_tokens: 256
    temperature: 0.7
    chat_history: ${inputs.chat_history}
    question: ${inputs.question}
    answer: ${math_planner.output}
  connection: AzureOpenAIConnection
  api: chat
- name: get_intent
  type: llm
  source:
    type: code
    path: get_intent.jinja2
  inputs:
    deployment_name: gpt-35-turbo
    chat_history: ${inputs.chat_history}
    question: ${inputs.question}
  connection: AzureOpenAIConnection
  api: chat
- name: math_planner
  type: python
  source:
    type: code
    path: math_planner.py
  inputs:
    connection: AzureOpenAIConnection
    intent: ${get_intent.output}
    deployment_name: gpt-35-turbo
